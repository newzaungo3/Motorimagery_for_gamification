{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.datasets import eegbci\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf,read_raw_edf,read_raw_gdf,read_raw_fif\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from mne.filter import construct_iir_filter,create_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from scipy.signal import iirfilter, sosfiltfilt\n",
    "import torch.optim as optim  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from torch.utils.data import Subset  \n",
    "from torch import nn  \n",
    "import torch.nn.functional as F  \n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz']\n",
      "['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz']\n",
      "160.0\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "300 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 300 events and 641 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_physio():\n",
    "    subject =['01','02','03','04','05','06','07','08','09','10','11','12','13','14']\n",
    "    path = \"/root/EEG_Model/dataset/physio/MNE-eegbci-data/files/eegmmidb/1.0.0\"\n",
    "    folders = os.listdir(path)\n",
    "    subject_count = 0\n",
    "    train_path = []\n",
    "    valid_path = []\n",
    "    count = 0\n",
    "    for fol in folders:\n",
    "        if count == 10:\n",
    "            break\n",
    "        else:\n",
    "            count +=1\n",
    "        for i in range (len (subject)):\n",
    "            if  subject[i] in ['01','02','03','04','05','06','07','08','09','10','13','14']:\n",
    "                pass\n",
    "            elif subject[i] in ['11','12']:\n",
    "                file = \"/root/EEG_Model/dataset/physio/MNE-eegbci-data/files/eegmmidb/1.0.0/{}/{}R{}.edf\".format(fol,fol, subject[i])\n",
    "                valid_path.append(file)\n",
    "            \n",
    "  \n",
    "    return valid_path\n",
    "\n",
    "def get_test_epoch(data_path,tmin,tmax,event_id,preprocess=False,ica=False):\n",
    "    \n",
    "    raw = concatenate_raws([read_raw_edf(f, preload=True,verbose='WARNING') for f in data_path])\n",
    "    raw_data = raw.copy()\n",
    "    eegbci.standardize(raw_data)\n",
    "    montage = mne.channels.make_standard_montage('standard_1005')\n",
    "    raw_data.set_montage(montage)\n",
    "    print(raw_data.info['ch_names'])\n",
    "    raw_data.rename_channels(lambda x: x.strip('.'))\n",
    "    print(raw_data.info['ch_names'])\n",
    "    print(raw_data.info['sfreq'])\n",
    "    \n",
    "    sfreq = 641\n",
    "    nyq = sfreq / 2 \n",
    "    f_p = 40.\n",
    "    \n",
    "    # Apply band-pass filter\n",
    "    if preprocess == True:\n",
    "        iir_param = dict(order=6, ftype='butter', output='sos')\n",
    "        #iir_param = construct_iir_filter(iir_param, 40, None, 1000, 'low', return_copy=False) \n",
    "         \n",
    "        #raw_data.filter(l_freq=0.05, h_freq=40.,fir_design='firwin', verbose=20)\n",
    "        raw_data.filter(l_freq=0.05, h_freq=75.,method = 'iir',iir_params=iir_param,phase='zero')\n",
    "        #raw_data.notch_filter(60,filter_length='auto', phase='zero')\n",
    "        raw_data.notch_filter(50,filter_length='auto', phase='zero')\n",
    "        \n",
    "    if ica == True:\n",
    "        ica = mne.preprocessing.ICA(n_components=64, max_iter=100)\n",
    "        ica.fit(raw_data)\n",
    "        ica.exclude = [1, 2]  # details on how we picked these are omitted here\n",
    "        ica.plot_properties(raw_data, picks=ica.exclude)\n",
    "        ica.apply(raw_data)\n",
    "    #2 electrode        \n",
    "    #raw_data.pick_channels(['C3','C4'])\n",
    "    #16 electrode\n",
    "    #raw_data.pick_channels(['FC3','FCz','FC5','C1','C2','C3','C4','C5','C6','Cz','CP3','CPz','CP4','P3','Pz','P4'])\n",
    "    events, event_id = events_from_annotations(raw_data,event_id=event_id)\n",
    "    picks = pick_types(raw_data.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "    reject_criteria = dict(eeg=100e-6)  #most frequency in this range is not brain components\n",
    "    \n",
    "    epochs = Epochs(raw_data, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None,preload=True)\n",
    "    labels = epochs.events[:, -1]\n",
    "    return epochs.get_data(),labels,epochs,raw_data\n",
    "    \n",
    "def get_data():\n",
    "    valid_path = get_physio()\n",
    "        \n",
    "    #tmin, tmax = -0.2, 0.4\n",
    "    tmin, tmax = 0, 4\n",
    "    event_id = dict(T1=0, T2=1)\n",
    "\n",
    "    valid_epoch,valid_labels,raw_epoch,raw = get_test_epoch(valid_path,tmin,tmax,event_id,False)\n",
    "    \n",
    "    return valid_epoch,valid_labels,raw_epoch,raw\n",
    "\n",
    "#train_epoch,valid_epoch,train_labels,valid_labels,raw_epoch,raw= get_data()\n",
    "valid_epoch,valid_labels,raw_epoch,raw= get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100068 events(epoch)\n",
    "# 64 channel\n",
    "# 961 Time(samples)\n",
    "#(event,channel,time)\n",
    "print(valid_epoch.shape)\n",
    "print(valid_labels.shape)\n",
    "print('---------------')\n",
    "#print(valid_epoch.shape)\n",
    "#print(valid_labels.shape)\n",
    "X = valid_epoch[:, np.newaxis,:,:]\n",
    "y = valid_labels\n",
    "print(X.shape)\n",
    "print(valid_epoch.shape[1])\n",
    "print(valid_labels)\n",
    "print(raw.info['ch_names'])\n",
    "print(raw.info['nchan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 2d convolution and 3d input (1,channel,timewindow)\n",
    "class gamenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gamenet,self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Sequential(\n",
    "            #in_channel = 16\n",
    "            #out_channel or Filter size = 100\n",
    "            #kernel size = (1,25)\n",
    "            #stride = 1\n",
    "            #padding = Same\n",
    "            #Relu\n",
    "            nn.Conv2d(1,100,kernel_size=(1,25),stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(100)\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            #in_channel = 100\n",
    "            #out_channel or Filter size = 100\n",
    "            #kernel size = (16,1)\n",
    "            #stride = 1\n",
    "            #padding = Valid\n",
    "            #Relu\n",
    "            #nn.Conv2d(100,100,kernel_size=(16,1),stride=1,padding='valid')\n",
    "            nn.Conv2d(100,100,kernel_size=(64,1),stride=1,padding='valid'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(100)\n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            #in_channel = 100\n",
    "            #out_channel = 50\n",
    "            #kernel size = (1,30)\n",
    "            #stride = 1\n",
    "            #padding = Same\n",
    "            #Relu\n",
    "            nn.Conv2d(100,50,kernel_size=(1,30),stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(50)\n",
    "        )\n",
    "        self.maxpooling1 = nn.MaxPool2d(kernel_size=(1,7),stride=5)\n",
    "        self.l4 = nn.Sequential(\n",
    "            #in_channel = 50\n",
    "            #out_channel = 50\n",
    "            #kernel size = (1,30)\n",
    "            #stride = 1\n",
    "            #padding = Same\n",
    "            #Relu\n",
    "            nn.Conv2d(50,50,kernel_size=(1,30),stride=1,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(50)\n",
    "        )\n",
    "        self.maxpooling2 = nn.MaxPool2d(kernel_size=(1,3),stride=2)\n",
    "        \n",
    "\n",
    "        self.flatten = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(3150),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(3150,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc5 = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.15)\n",
    "        )\n",
    "        self.softmax = nn.Sequential(\n",
    "            nn.Linear(32,2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.maxpooling1(out)\n",
    "        out = self.l4(out)\n",
    "        out = self.maxpooling2(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gamenet(\n",
       "  (l1): Sequential(\n",
       "    (0): Conv2d(1, 100, kernel_size=(1, 25), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (l2): Sequential(\n",
       "    (0): Conv2d(100, 100, kernel_size=(64, 1), stride=(1, 1), padding=valid)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (l3): Sequential(\n",
       "    (0): Conv2d(100, 50, kernel_size=(1, 30), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpooling1): MaxPool2d(kernel_size=(1, 7), stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "  (l4): Sequential(\n",
       "    (0): Conv2d(50, 50, kernel_size=(1, 30), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpooling2): MaxPool2d(kernel_size=(1, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): BatchNorm1d(3150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=3150, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (fc4): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (fc5): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (fc6): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.15, inplace=False)\n",
       "  )\n",
       "  (softmax): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gamenet()\n",
    "path = '/root/EEG_Model/save_weight/Physionet_Gamenet_64elec_executedImagine_Wandb_Newcuda-423-bestacc86.00.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 64, 641])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "#(600, 1, 64, 641)\n",
    "test_input = torch.rand(50,1,64,641)\n",
    "output = model(test_input)\n",
    "print(test_input.shape)\n",
    "print(output)\n",
    "\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71ee62090f476f7f208daa0d546a5a64db59508b1a22febc715667ce49424855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
