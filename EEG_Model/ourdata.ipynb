{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from common import setup_dataflow,EEG,getepoch,do_plot,create_dataloader\n",
    "import wandb\n",
    "from mne.datasets import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/EEG_Model/dataset/finetune_EEG/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R04.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R06.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R08.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R10.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R04.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R06.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fz', 'C3', 'Cz', 'C4', 'Pz', 'PO7', 'Oz', 'PO8', 'STIM MARKERS']\n",
      "250.0\n",
      "['C3', 'C4', 'STIM MARKERS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R08.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n",
      "/root/EEG_Model/common.py:255: RuntimeWarning: This filename (/root/EEG_Model/dataset/finetune_EEG/S009/S009R10.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif( path_file , preload=True, verbose='WARNING' )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fz', 'C3', 'Cz', 'C4', 'Pz', 'PO7', 'Oz', 'PO8', 'STIM MARKERS']\n",
      "250.0\n",
      "['C3', 'C4', 'STIM MARKERS']\n",
      "Raw done\n",
      "Filtering raw data in 4 contiguous segments\n",
      "Setting up band-pass filter from 8 - 14 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 14.00 Hz\n",
      "- Upper transition bandwidth: 3.50 Hz (-6 dB cutoff frequency: 15.75 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n",
      "Filter done\n"
     ]
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = \"/root/EEG_Model/dataset/recorded_EEG/\"\n",
    "path = \"/root/EEG_Model/dataset/finetune_EEG/\"\n",
    "#subject to run\n",
    "#runs = [3,5,7,9]\n",
    "runs = [4,6,8,10]\n",
    "#runs = [7,8,9,10]\n",
    "subjects = [9]\n",
    "#recorded eeg class\n",
    "eeg = EEG(path, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "\n",
    "print(\"Raw done\")\n",
    "# apply filter \n",
    "raw=raw.notch_filter([50,75,100])\n",
    "raw=raw.filter(8,14, method='fir', verbose=20)\n",
    "print(\"Filter done\")\n",
    "#raw=eeg.raw_ica()\n",
    "#eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 events found\n",
      "Event IDs: [1 2 4]\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 80 events and 1751 original time points ...\n",
      "4 bad epochs dropped\n",
      "(76, 2, 1751)\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/EEG_Model/common.py:280: RuntimeWarning: No matching events found for 3 (event id 3)\n",
      "  epochs = mne.Epochs(\n"
     ]
    }
   ],
   "source": [
    "epochs=eeg.epochs(raw,tmin=0,tmax=7,baseline=(0,2))\n",
    "#X = X[:, :,np.newaxis,:]\n",
    "X, y = eeg.get_X_y(epochs)\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (53, 2, 1751) (53,)\n",
      "Test size (23, 2, 1751) (23,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "print('Train size',X_train.shape, y_train.shape)\n",
    "print('Test size',X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1751\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "num_step =math.ceil(len(train_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnewturno\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/EEG_Model/wandb/run-20230114_082651-1jmtxt0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/newturno/Motor-Imagery-New/runs/1jmtxt0g\" target=\"_blank\">CNN_S09_MI</a></strong> to <a href=\"https://wandb.ai/newturno/Motor-Imagery-New\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wand setup\n",
    "wandb.login()\n",
    "wand = wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Motor-Imagery-New\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"CNN_S09_MI\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.0000001,\n",
    "      \"architecture\": \"CNN2D\",\n",
    "      \"dataset\": \"Recorded\",\n",
    "      \"epochs\": 100000,\n",
    "      \"weightname\":\"Sunsun_S09_new_MI\",\n",
    "      \"num_step_per_epoch\" : num_step, \n",
    "      }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvNet,CNN2D\n",
    "from torchsummary import summary\n",
    "net = ConvNet().cuda()\n",
    "\n",
    "#summary(net, (2, 641),32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000, Tr Loss: 0.7729, Tr Acc: 41.5094, Val Loss: 0.6931, Val Acc: 52.1739\n",
      "Epoch 101/100000, Tr Loss: 0.7139, Tr Acc: 52.8302, Val Loss: 0.6985, Val Acc: 47.8261\n",
      "Epoch 201/100000, Tr Loss: 0.7331, Tr Acc: 43.3962, Val Loss: 0.7034, Val Acc: 43.4783\n",
      "Epoch 301/100000, Tr Loss: 0.7070, Tr Acc: 45.2830, Val Loss: 0.7019, Val Acc: 34.7826\n",
      "Epoch 401/100000, Tr Loss: 0.6992, Tr Acc: 60.3774, Val Loss: 0.7053, Val Acc: 43.4783\n",
      "Epoch 501/100000, Tr Loss: 0.6992, Tr Acc: 50.9434, Val Loss: 0.7059, Val Acc: 39.1304\n",
      "Epoch 601/100000, Tr Loss: 0.6213, Tr Acc: 66.0377, Val Loss: 0.7029, Val Acc: 34.7826\n",
      "Epoch 701/100000, Tr Loss: 0.5913, Tr Acc: 71.6981, Val Loss: 0.7076, Val Acc: 52.1739\n",
      "Epoch 801/100000, Tr Loss: 0.6815, Tr Acc: 56.6038, Val Loss: 0.7018, Val Acc: 52.1739\n",
      "Epoch 901/100000, Tr Loss: 0.6009, Tr Acc: 67.9245, Val Loss: 0.7018, Val Acc: 52.1739\n",
      "Epoch 1001/100000, Tr Loss: 0.6031, Tr Acc: 69.8113, Val Loss: 0.6997, Val Acc: 56.5217\n",
      "Epoch 1101/100000, Tr Loss: 0.5888, Tr Acc: 73.5849, Val Loss: 0.7004, Val Acc: 56.5217\n",
      "Epoch 1201/100000, Tr Loss: 0.5816, Tr Acc: 69.8113, Val Loss: 0.7023, Val Acc: 56.5217\n",
      "Epoch 1301/100000, Tr Loss: 0.5622, Tr Acc: 73.5849, Val Loss: 0.7026, Val Acc: 56.5217\n",
      "Epoch 1401/100000, Tr Loss: 0.5253, Tr Acc: 84.9057, Val Loss: 0.6961, Val Acc: 56.5217\n",
      "Epoch 1501/100000, Tr Loss: 0.5350, Tr Acc: 73.5849, Val Loss: 0.7018, Val Acc: 56.5217\n",
      "Epoch 1601/100000, Tr Loss: 0.5232, Tr Acc: 84.9057, Val Loss: 0.7006, Val Acc: 60.8696\n",
      "Epoch 1701/100000, Tr Loss: 0.5178, Tr Acc: 86.7925, Val Loss: 0.7001, Val Acc: 52.1739\n",
      "Epoch 1801/100000, Tr Loss: 0.4825, Tr Acc: 84.9057, Val Loss: 0.7046, Val Acc: 52.1739\n",
      "Epoch 1901/100000, Tr Loss: 0.4522, Tr Acc: 86.7925, Val Loss: 0.7043, Val Acc: 56.5217\n",
      "Epoch 2001/100000, Tr Loss: 0.4769, Tr Acc: 86.7925, Val Loss: 0.7062, Val Acc: 52.1739\n",
      "Epoch 2101/100000, Tr Loss: 0.4784, Tr Acc: 84.9057, Val Loss: 0.7068, Val Acc: 56.5217\n",
      "Epoch 2201/100000, Tr Loss: 0.5121, Tr Acc: 81.1321, Val Loss: 0.7108, Val Acc: 52.1739\n",
      "Epoch 2301/100000, Tr Loss: 0.4346, Tr Acc: 88.6792, Val Loss: 0.7001, Val Acc: 56.5217\n",
      "Epoch 2401/100000, Tr Loss: 0.4448, Tr Acc: 90.5660, Val Loss: 0.7049, Val Acc: 56.5217\n",
      "Epoch 2501/100000, Tr Loss: 0.4148, Tr Acc: 92.4528, Val Loss: 0.7009, Val Acc: 56.5217\n",
      "Epoch 2601/100000, Tr Loss: 0.3757, Tr Acc: 92.4528, Val Loss: 0.6997, Val Acc: 56.5217\n",
      "Epoch 2701/100000, Tr Loss: 0.4166, Tr Acc: 92.4528, Val Loss: 0.7052, Val Acc: 52.1739\n",
      "Epoch 2801/100000, Tr Loss: 0.3882, Tr Acc: 96.2264, Val Loss: 0.7040, Val Acc: 56.5217\n",
      "Epoch 2901/100000, Tr Loss: 0.3890, Tr Acc: 94.3396, Val Loss: 0.7067, Val Acc: 56.5217\n",
      "Epoch 3001/100000, Tr Loss: 0.3714, Tr Acc: 96.2264, Val Loss: 0.7059, Val Acc: 56.5217\n",
      "Epoch 3101/100000, Tr Loss: 0.3907, Tr Acc: 94.3396, Val Loss: 0.7075, Val Acc: 60.8696\n",
      "Epoch 3201/100000, Tr Loss: 0.3528, Tr Acc: 94.3396, Val Loss: 0.6995, Val Acc: 52.1739\n",
      "Epoch 3301/100000, Tr Loss: 0.3469, Tr Acc: 94.3396, Val Loss: 0.7115, Val Acc: 52.1739\n",
      "Epoch 3401/100000, Tr Loss: 0.3576, Tr Acc: 98.1132, Val Loss: 0.7090, Val Acc: 56.5217\n",
      "Epoch 3501/100000, Tr Loss: 0.3310, Tr Acc: 96.2264, Val Loss: 0.7106, Val Acc: 60.8696\n",
      "Epoch 3601/100000, Tr Loss: 0.3162, Tr Acc: 98.1132, Val Loss: 0.7137, Val Acc: 52.1739\n",
      "Epoch 3701/100000, Tr Loss: 0.3107, Tr Acc: 98.1132, Val Loss: 0.7132, Val Acc: 56.5217\n",
      "Epoch 3801/100000, Tr Loss: 0.3158, Tr Acc: 96.2264, Val Loss: 0.7119, Val Acc: 56.5217\n",
      "Epoch 3901/100000, Tr Loss: 0.3201, Tr Acc: 96.2264, Val Loss: 0.7131, Val Acc: 56.5217\n",
      "Epoch 4001/100000, Tr Loss: 0.2613, Tr Acc: 98.1132, Val Loss: 0.7142, Val Acc: 60.8696\n",
      "Epoch 4101/100000, Tr Loss: 0.2823, Tr Acc: 96.2264, Val Loss: 0.7113, Val Acc: 56.5217\n",
      "Epoch 4201/100000, Tr Loss: 0.2747, Tr Acc: 96.2264, Val Loss: 0.7146, Val Acc: 60.8696\n",
      "Epoch 4301/100000, Tr Loss: 0.2624, Tr Acc: 98.1132, Val Loss: 0.7118, Val Acc: 56.5217\n",
      "Epoch 4401/100000, Tr Loss: 0.2777, Tr Acc: 100.0000, Val Loss: 0.7100, Val Acc: 56.5217\n",
      "Epoch 4501/100000, Tr Loss: 0.2492, Tr Acc: 100.0000, Val Loss: 0.7230, Val Acc: 56.5217\n",
      "Epoch 4601/100000, Tr Loss: 0.2488, Tr Acc: 100.0000, Val Loss: 0.7087, Val Acc: 60.8696\n",
      "Epoch 4701/100000, Tr Loss: 0.2345, Tr Acc: 100.0000, Val Loss: 0.7183, Val Acc: 56.5217\n",
      "Epoch 4801/100000, Tr Loss: 0.2579, Tr Acc: 100.0000, Val Loss: 0.7128, Val Acc: 60.8696\n",
      "Epoch 4901/100000, Tr Loss: 0.2347, Tr Acc: 98.1132, Val Loss: 0.7195, Val Acc: 60.8696\n",
      "Epoch 5001/100000, Tr Loss: 0.2329, Tr Acc: 100.0000, Val Loss: 0.7241, Val Acc: 60.8696\n",
      "Epoch 5101/100000, Tr Loss: 0.1930, Tr Acc: 100.0000, Val Loss: 0.7172, Val Acc: 56.5217\n",
      "Epoch 5201/100000, Tr Loss: 0.1843, Tr Acc: 98.1132, Val Loss: 0.7200, Val Acc: 60.8696\n",
      "Epoch 5301/100000, Tr Loss: 0.1886, Tr Acc: 100.0000, Val Loss: 0.7201, Val Acc: 60.8696\n",
      "Epoch 5401/100000, Tr Loss: 0.1846, Tr Acc: 100.0000, Val Loss: 0.7298, Val Acc: 60.8696\n",
      "Epoch 5501/100000, Tr Loss: 0.2019, Tr Acc: 100.0000, Val Loss: 0.7260, Val Acc: 56.5217\n",
      "Epoch 5601/100000, Tr Loss: 0.1913, Tr Acc: 100.0000, Val Loss: 0.7229, Val Acc: 60.8696\n",
      "Epoch 5701/100000, Tr Loss: 0.1641, Tr Acc: 100.0000, Val Loss: 0.7233, Val Acc: 60.8696\n",
      "Epoch 5801/100000, Tr Loss: 0.1669, Tr Acc: 100.0000, Val Loss: 0.7268, Val Acc: 60.8696\n",
      "Epoch 5901/100000, Tr Loss: 0.1752, Tr Acc: 100.0000, Val Loss: 0.7297, Val Acc: 60.8696\n",
      "Epoch 6001/100000, Tr Loss: 0.1668, Tr Acc: 100.0000, Val Loss: 0.7249, Val Acc: 52.1739\n",
      "Epoch 6101/100000, Tr Loss: 0.1626, Tr Acc: 100.0000, Val Loss: 0.7330, Val Acc: 56.5217\n",
      "Epoch 6201/100000, Tr Loss: 0.1666, Tr Acc: 100.0000, Val Loss: 0.7295, Val Acc: 60.8696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      5\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m train_loss,valid_loss,train_accuracy,valid_accuracy \u001b[39m=\u001b[39mtrain(\n\u001b[1;32m      8\u001b[0m     model \u001b[39m=\u001b[39;49m net,\n\u001b[1;32m      9\u001b[0m     loader_train \u001b[39m=\u001b[39;49m train_loader,\n\u001b[1;32m     10\u001b[0m     loader_test \u001b[39m=\u001b[39;49m test_loader,\n\u001b[1;32m     11\u001b[0m     vail_loader \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     12\u001b[0m     optimizer \u001b[39m=\u001b[39;49m optimizer  ,\n\u001b[1;32m     13\u001b[0m     criterion \u001b[39m=\u001b[39;49m criterion ,\n\u001b[1;32m     14\u001b[0m     device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     wand \u001b[39m=\u001b[39;49m wand\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     19\u001b[0m wandb\u001b[39m.\u001b[39malert(\n\u001b[1;32m     20\u001b[0m             title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFinish\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m             text\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFinishing training\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m         )\n",
      "File \u001b[0;32m~/EEG_Model/common.py:113\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, loader_test, optimizer, criterion, device, wand, vail_loader, cross)\u001b[0m\n\u001b[1;32m    111\u001b[0m iter_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    112\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 113\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    115\u001b[0m metrics \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtrain/train_loss\u001b[39m\u001b[39m\"\u001b[39m: loss}\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m config\u001b[39m.\u001b[39mnum_step_per_epoch:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# 🐝 Log train metrics to wandb \u001b[39;00m\n",
      "File \u001b[0;32m~/EEG_Model/.venv/lib/python3.8/site-packages/torch/optim/optimizer.py:112\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m obj, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(profile_name):\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/EEG_Model/.venv/lib/python3.8/site-packages/torch/autograd/profiler.py:443\u001b[0m, in \u001b[0;36mrecord_function.__init__\u001b[0;34m(self, name, args)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[39m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from common import train\n",
    "config = wand.config\n",
    "optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "\n",
    "train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "    model = net,\n",
    "    loader_train = train_loader,\n",
    "    loader_test = test_loader,\n",
    "    vail_loader = None,\n",
    "    optimizer = optimizer  ,\n",
    "    criterion = criterion ,\n",
    "    device = 'cuda',\n",
    "    wand = wand\n",
    ")\n",
    "\n",
    "\n",
    "wandb.alert(\n",
    "            title='Finish',\n",
    "            text=f'Finishing training',\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune data\n",
    "You need to freeze layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./save_weight/Krittin_S54_MI/0.6929_Krittin_S54_MI_0.6929_52.1739'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = net.state_dict()\n",
    "parms.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze layer 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad and 'layer1' in name:\n",
    "        param.requires_grad = False\n",
    "    if param.requires_grad and 'layer2' in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home directory + datasets folder\n",
    "path = \"/root/EEG_Model/dataset/finetune_EEG/\"\n",
    "#subject to run\n",
    "runs = [4,6,8,10]\n",
    "subjects = [8]\n",
    "#recorded eeg class\n",
    "eeg = EEG(path, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "\n",
    "print(\"Raw done\")\n",
    "# apply filter \n",
    "raw=raw.notch_filter([50,75,100])\n",
    "raw=raw.filter( 8,14, method='fir', verbose=20)\n",
    "print(\"Filter done\")\n",
    "\n",
    "epochs=eeg.epochs(raw,tmin=0,tmax=7,baseline=(0,2))\n",
    "#X = X[:, :,np.newaxis,:]\n",
    "X, y = eeg.get_X_y(epochs)\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "\n",
    "print('train size',X_train.shape, y_train.shape)\n",
    "print('Test size',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1751\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "num_step =math.ceil(len(train_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "wand = wandb.init(\n",
    "        \n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Motor-Imagery\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"CNN_S08_New_MI\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.0000001,\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"Nutapol T.\",\n",
    "      \"epochs\": 300000,\n",
    "      \"weightname\":\"Krittin_S08_Finetune_MI\",\n",
    "      \"num_step_per_epoch\" : num_step, \n",
    "        \n",
    "      }\n",
    "    )\n",
    "\n",
    "config = wand.config\n",
    "print(config.num_step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import train\n",
    "config = wand.config\n",
    "optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "\n",
    "train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "    model = net,\n",
    "    loader_train = train_loader,\n",
    "    loader_test = test_loader,\n",
    "    vail_loader = None,\n",
    "    optimizer = optimizer  ,\n",
    "    criterion = criterion ,\n",
    "    device = 'cuda',\n",
    "    wand = wand\n",
    ")\n",
    "\n",
    "wandb.alert(\n",
    "            title='Finish',\n",
    "            text=f'Finishing training',\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvNet,CNN2D\n",
    "from torchsummary import summary\n",
    "net = ConvNet().cuda()\n",
    "net.load_state_dict(torch.load('./save_weight/Sunsun_findtune_MI/0.4597_Sunsun_findtune_MI_0.4597_83.3333'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home directory + datasets folder\n",
    "path = \"/root/EEG_Model/dataset/finetune_EEG/\"\n",
    "#subject to run\n",
    "runs = [4]\n",
    "subjects = [20]\n",
    "#recorded eeg class\n",
    "eeg = EEG(path, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "\n",
    "print(\"Raw done\")\n",
    "# apply filter \n",
    "raw=raw.notch_filter([50,75,100])\n",
    "raw=raw.filter( 8,14, method='fir', verbose=20)\n",
    "print(\"Filter done\")\n",
    "\n",
    "epochs=eeg.epochs(raw,tmin=0,tmax=7,baseline=(0,2))\n",
    "#X = X[:, :,np.newaxis,:]\n",
    "X, y = eeg.get_X_y(epochs)\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1751\n",
    "test_loader = create_dataloader(X, y, batch_size=batch_size)\n",
    "\n",
    "num_step =math.ceil(len(test_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "num_epochs = 1\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "old_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    net.eval()\n",
    "    for i, (items, classes) in enumerate(test_loader):\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        \n",
    "        if cuda.is_available():\n",
    "            items = items.cuda(0)\n",
    "            classes = classes.cuda(0)\n",
    "        \n",
    "        outputs = net(items)\n",
    "        #loss += criterion(outputs, classes).item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        for i in range(predicted.shape[0]):\n",
    "            \n",
    "            if predicted[i] == classes.data[i]:\n",
    "                correct += 1\n",
    "            \n",
    "        #correct += (predicted == classes.data).sum()\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "    #valid_loss.append(loss/iterations)\n",
    "    #correct_scalar = np.array([correct.clone().cpu()])[0]\n",
    "    valid_accuracy.append(correct / len(test_loader.dataset) * 100.0)\n",
    "print (' Val Acc: %.4f'\n",
    "                   %(valid_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted)\n",
    "print(classes.data.cpu().numpy())\n",
    "y_true = classes.data.cpu().numpy()\n",
    "y_pred = y_pred=predicted.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71ee62090f476f7f208daa0d546a5a64db59508b1a22febc715667ce49424855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
